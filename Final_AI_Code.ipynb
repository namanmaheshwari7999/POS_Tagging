{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Project Code - Viterbi Algorithm for POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Members :  \n",
    "18ucc002 : Deepesh Kanodia  \n",
    "18ucc058 : Naman Maheshwari  \n",
    "18ucc160 : Manav Ladha  \n",
    "18ucs179 : Shreena Parekh  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The entire code is majorly divided into 5 segments:\n",
    "\n",
    "1. **Importing Necessaries**   \n",
    "    1.1 Importing Libraries  \n",
    "    1.2 Importing Dataset\n",
    "  \n",
    "2. **Data Preprocessing**   \n",
    "    2.1 Extracting from .txt file   \n",
    "    2.2 Removing empty list  \n",
    "    2.3 Converting to Tuple  \n",
    "    2.4 Unique Tags  \n",
    "    2.5 Unique Words - Vocabulary  \n",
    "  \n",
    "3. **Computing Probabilities**  \n",
    "    3.1 Map Tag to Index     \n",
    "    3.2 Compute Word to Tag Count Matrix   \n",
    "    3.3 Compute Tag to Tag Count Matrix    \n",
    "    3.4 Compute Emission Probability Matrix   \n",
    "    3.5 Compute Transition Probability Matrix   \n",
    "  \n",
    "4. **Viterbi Algorithm**   \n",
    "    4.1 Viterbi Decoding Function  \n",
    "    4.2 Backtracking Function  \n",
    "    4.3 Map output state sequence   \n",
    "  \n",
    "5. **Testing**   \n",
    "    5.1 Test code on an exapmle  \n",
    "    5.2 Test code on entire testing set  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pprint, time\n",
    "from collections import defaultdict\n",
    "import statistics \n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = open(\"test.txt\", \"r\")\n",
    "train_file = open(\"train.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Extracting from .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_of_lists = []\n",
    "for line in train_file:\n",
    "    stripped_line = line.strip()\n",
    "    line_list = stripped_line.split()\n",
    "    train_list_of_lists.append(line_list)\n",
    "\n",
    "train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples :  220663\n"
     ]
    }
   ],
   "source": [
    "train_list_of_lists[30:50]\n",
    "print(\"Number of Training Examples : \",len(train_list_of_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list_of_lists = []\n",
    "for line in test_file:\n",
    "    stripped_line = line.strip()\n",
    "    line_list = stripped_line.split()\n",
    "    test_list_of_lists.append(line_list)\n",
    "\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Testing Examples :  49389\n"
     ]
    }
   ],
   "source": [
    "test_list_of_lists[30:50]\n",
    "print(\"Number of Testing Examples : \",len(test_list_of_lists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Removing empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples after removing empty lists :  211727\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_list_of_lists = [ele for ele in train_list_of_lists if ele!=[]]\n",
    "print(\"Number of Training Examples after removing empty lists : \",len(train_list_of_lists))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Converting to Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_list_pos =[]\n",
    "for i in train_list_of_lists :\n",
    "    k = i[:2]\n",
    "    j = tuple(k)\n",
    "    final_train_list_pos.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_list_pos =[]\n",
    "for i in test_list_of_lists :\n",
    "    k = i[:2]\n",
    "    j = tuple(k)\n",
    "    final_test_list_pos.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Confidence', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('pound', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('widely', 'RB'),\n",
       " ('expected', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('take', 'VB'),\n",
       " ('another', 'DT')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(final_train_list_pos))\n",
    "final_train_list_pos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Rockwell', 'NNP'),\n",
       " ('International', 'NNP'),\n",
       " ('Corp.', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('Tulsa', 'NNP'),\n",
       " ('unit', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('signed', 'VBD'),\n",
       " ('a', 'DT')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(final_test_list_pos))\n",
    "final_test_list_pos[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Unique POS tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NN', 'RB', ',', 'VBP', 'JJS', '(', 'PRP$', 'VBN', 'WP', 'FW', '.', 'EX', '$', 'PRP', 'WP$', 'WDT', 'VBZ', 'VB', 'VBG', 'JJ', 'CD', '#', ')', 'PDT', 'MD', 'RP', 'CC', 'SYM', 'IN', 'RBS', \"''\", 'NNP', 'UH', 'VBD', 'NNS', ':', 'TO', 'JJR', 'WRB', 'RBR', 'POS', 'DT', '``', 'NNPS']\n"
     ]
    }
   ],
   "source": [
    "unique_pos_tags = list({tag for word,tag in final_train_list_pos})\n",
    "print(unique_pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique POS Tag in Training Set :  44\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Unique POS Tag in Training Set : \",len(unique_pos_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Unique Words - Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Words in Training Set :  19122\n"
     ]
    }
   ],
   "source": [
    "# check total words in vocabulary\n",
    "vocab = {word for word,tag in final_train_list_pos}\n",
    "print(\"Number of Unique Words in Training Set : \",len(vocab))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Map index to Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map the state tags to unique indices i.e. 0 : NN , 1 : DT\n",
    "\n",
    "def assign_index_tag(unique_pos_tags):\n",
    "    tag_map={}\n",
    "    vals = list(range(0,len(unique_pos_tags)))\n",
    "    \n",
    "    for i , tag in enumerate(unique_pos_tags):\n",
    "        #tag_map[tag] = i\n",
    "        tag_map[i] = tag\n",
    "        \n",
    "    #tag_map[unique_pos_tags]=vals\n",
    "    return tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'NN', 1: 'RB', 2: ',', 3: 'VBP', 4: 'JJS', 5: '(', 6: 'PRP$', 7: 'VBN', 8: 'WP', 9: 'FW', 10: '.', 11: 'EX', 12: '$', 13: 'PRP', 14: 'WP$', 15: 'WDT', 16: 'VBZ', 17: 'VB', 18: 'VBG', 19: 'JJ', 20: 'CD', 21: '#', 22: ')', 23: 'PDT', 24: 'MD', 25: 'RP', 26: 'CC', 27: 'SYM', 28: 'IN', 29: 'RBS', 30: \"''\", 31: 'NNP', 32: 'UH', 33: 'VBD', 34: 'NNS', 35: ':', 36: 'TO', 37: 'JJR', 38: 'WRB', 39: 'RBR', 40: 'POS', 41: 'DT', 42: '``', 43: 'NNPS'}\n"
     ]
    }
   ],
   "source": [
    "tag_map = assign_index_tag(unique_pos_tags)\n",
    "print(tag_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Compute Word to Tag Count Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the word to tag count matrix which stores the count of each word w being in each state t\n",
    "\n",
    "def compute_count_matrix_wordtotag(vocab,unique_pos_tags,train_set):\n",
    "    \n",
    "    count_mat_wt = pd.DataFrame(0,columns = list(vocab), index=list(unique_pos_tags))\n",
    "    count_mat_t = pd.DataFrame(0,columns = ['count'], index=list(unique_pos_tags))\n",
    "    \n",
    "    for w,t in train_set :\n",
    "        count_mat_t.loc[t,'count']+=1\n",
    "        count_mat_wt.loc[t,w]+=1  \n",
    "  \n",
    "    return count_mat_t,count_mat_wt\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mat_t,count_mat_wt = compute_count_matrix_wordtotag(vocab,unique_pos_tags,final_train_list_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"WORD to TAG COUNT MATRIX\")\n",
    "count_mat_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG COUNT MATRIX\n",
      "      count\n",
      "NN    30147\n",
      "RB     6607\n",
      ",     10770\n",
      "VBP    2868\n",
      "JJS     374\n",
      "(       274\n",
      "PRP$   1881\n",
      "VBN    4763\n",
      "WP      529\n",
      "FW       38\n",
      ".      8827\n",
      "EX      206\n",
      "$      1750\n",
      "PRP    3820\n",
      "WP$      35\n",
      "WDT     955\n",
      "VBZ    4648\n",
      "VB     6017\n",
      "VBG    3272\n",
      "JJ    13085\n",
      "CD     8315\n",
      "#        36\n",
      ")       281\n",
      "PDT      55\n",
      "MD     2167\n",
      "RP       83\n",
      "CC     5372\n",
      "SYM       6\n",
      "IN    22764\n",
      "RBS     191\n",
      "''     1493\n",
      "NNP   19884\n",
      "UH       15\n",
      "VBD    6745\n",
      "NNS   13619\n",
      ":      1047\n",
      "TO     5081\n",
      "JJR     853\n",
      "WRB     478\n",
      "RBR     321\n",
      "POS    1769\n",
      "DT    18335\n",
      "``     1531\n",
      "NNPS    420\n"
     ]
    }
   ],
   "source": [
    "print(\"TAG COUNT MATRIX\")\n",
    "print(count_mat_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Compute Tag to Tag Count Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the tag to tag count matrix which stores the count of each tag t1 being preceded by each state t2\n",
    "\n",
    "def compute_count_matrix_tagtotag(vocab,unique_pos_tags,train_set):\n",
    "    \n",
    "    count_mat_tt = pd.DataFrame(0,columns = list(unique_pos_tags), index=list(unique_pos_tags))\n",
    "    \n",
    "    for i in range(0,len(train_set)-1) :\n",
    "        cur_tag = train_set[i][1]\n",
    "        nxt_tag = train_set[i+1][1]\n",
    "        count_mat_tt.loc[cur_tag,nxt_tag]+=1   \n",
    "  \n",
    "    return count_mat_tt\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mat_tt = compute_count_matrix_tagtotag(vocab,unique_pos_tags,final_train_list_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TAG to TAG COUNT MATRIX\")\n",
    "count_mat_tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Compute Emission Probability Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the emission probability matrix using the word to tag count matrix and tag count matrix\n",
    "\n",
    "def compute_emission_matrix(count_mat_t,count_mat_wt):\n",
    "    emission_mat = pd.DataFrame(0,columns = list(vocab), index=list(unique_pos_tags))\n",
    "    \n",
    "    for t in unique_pos_tags:\n",
    "        \n",
    "        for w in vocab:\n",
    "            emission_mat.loc[t,w]=count_mat_wt.loc[t,w]/count_mat_t.loc[t,'count']\n",
    "    \n",
    "    return emission_mat\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emmision_mat = compute_emission_matrix(count_mat_t,count_mat_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EMISSION MATRIX\")\n",
    "emmision_mat[1:10][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmision_mat.loc['NNP','September']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Compute Transition Probability Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the transition probability matrix using the tag to tag count matrix and tag count matrix\n",
    "\n",
    "def compute_transition_matrixx(count_mat_t,count_mat_tt):\n",
    "    \n",
    "    transition_mat = pd.DataFrame(0,columns = list(unique_pos_tags), index=list(unique_pos_tags))\n",
    "    \n",
    "    for t1 in unique_pos_tags:\n",
    "        for t2 in unique_pos_tags:\n",
    "             transition_mat.loc[t1,t2]=count_mat_tt.loc[t1,t2]/count_mat_t.loc[t1,'count']\n",
    "    \n",
    "    return  transition_mat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_mat = compute_transition_matrixx(count_mat_t,count_mat_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009839195241941405\n"
     ]
    }
   ],
   "source": [
    "print(transition_mat['POS']['NNS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute the trelis matrix and backpointer matrix to keep track of maximum probablity value and path\n",
    "\n",
    "def Viterbi (tag_map , emmision_mat , transition_mat , init_dist , end_dist , observation):    \n",
    "        \n",
    "    N = transition_mat.shape[0]\n",
    "    T = len(observation)\n",
    "    \n",
    "    rows = N + 2\n",
    "    cols = T + 1\n",
    "     \n",
    "    trelis = np.zeros((rows, cols),dtype='float64')    \n",
    "    backpointer = np.zeros((rows, cols),dtype='float64')\n",
    "    start_symbol = observation[0]\n",
    "    \n",
    "    transition_matrix = transition_mat.values\n",
    "    if start_symbol not in emmision_mat.columns:\n",
    "            emmision_mat[start_symbol] = 0.00001\n",
    "        \n",
    "    #INITIALIZATOIN\n",
    "   \n",
    "    for s in range(0,N):\n",
    "        \n",
    "        trelis[s][0] = init_dist[s] * emmision_mat.loc[tag_map[s] ,start_symbol] \n",
    "        backpointer[s][0] = 0\n",
    "        \n",
    "        \n",
    "    #TRAVERSING\n",
    "    \n",
    "    for t in range(1,T):\n",
    "        \n",
    "        cur_obs = observation[t]\n",
    "        if cur_obs not in emmision_mat.columns:\n",
    "            emmision_mat[cur_obs]=0.00001\n",
    "           \n",
    "        for s in range(0,N):\n",
    "           \n",
    "            max_val = -1\n",
    "            max_pos = -1\n",
    "            for pre_s in range(0,N):\n",
    "                pre_viterbi = trelis[pre_s][t-1]\n",
    "                transition_val = transition_matrix[pre_s][s]\n",
    "                \n",
    "                val = pre_viterbi * transition_val\n",
    "                \n",
    "                if val>max_val:\n",
    "                    max_val = val\n",
    "                    max_pos = pre_s\n",
    "                    \n",
    "            trelis[s][t] = max_val * emmision_mat.loc[tag_map[s],cur_obs]\n",
    "            backpointer[s][t] = max_pos\n",
    "            \n",
    "   \n",
    "     \n",
    "    #TERMINATING\n",
    "    \n",
    "    max_end_value = -1\n",
    "    max_end_position = -1\n",
    "    for s in range(0,N):\n",
    "        \n",
    "        end_viterbi = trelis[s][T-1]\n",
    "        end_transition_val = end_dist[s]\n",
    "        \n",
    "        end_value = end_viterbi * end_transition_val\n",
    "        \n",
    "        if end_value > max_end_value:\n",
    "            max_end_value = end_value\n",
    "            max_end_pos = s\n",
    "            \n",
    "    trelis[N][T] = max_end_value\n",
    "    backpointer[N][T] = max_end_pos\n",
    "    \n",
    "    return trelis , backpointer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Backtrace Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the optimal sequence of state indices from the Backpointer matrix\n",
    "\n",
    "def backtrace_seq(backpointer):\n",
    "\n",
    "    last_state = backpointer[-2][-1]\n",
    "    back_df = pd.DataFrame(data = backpointer)  \n",
    "\n",
    "    max_occur_list = []\n",
    "    \n",
    "    for col in back_df.columns[1:-1]:\n",
    "        \n",
    "        max_occur = int(stats.mode(list(back_df[col]))[0])\n",
    "        max_occur_list.append(max_occur)\n",
    "   \n",
    "    \n",
    "    max_occur_list.append(int(last_state))\n",
    "    return max_occur_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Map Output Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to map the sequence of state indices to actual state tag names\n",
    "\n",
    "def index_output_seq(output_seq , tag_map):\n",
    "    optimal_states = []\n",
    "    for index in output_seq:\n",
    "        optimal_states.append(tag_map[index])\n",
    "        \n",
    "    return optimal_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Testing Algorithm on an Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting initial parameteres like number of states , initial probability distribution and final probability distribution\n",
    "\n",
    "N = transition_mat.shape[0]\n",
    "init_dist = list(transition_mat.loc['.',:])\n",
    "end_dist = list(transition_mat['.'])\n",
    "\n",
    "observation = ['I','have','a','dog']\n",
    "original_result = ['PRP','VBP','DT','NN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "trelis , backpointer = Viterbi (tag_map , emmision_mat , transition_mat , init_dist , end_dist , observation)\n",
    "max_occur_list = backtrace_seq(backpointer)\n",
    "output_state_seq = index_output_seq(max_occur_list , tag_map)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 3, 41, 0]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_occur_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRP', 'VBP', 'DT', 'NN']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_state_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE ALGORITHM :  100.0 %\n",
      "TIME TAKEN :  0.012966632843017578\n"
     ]
    }
   ],
   "source": [
    "correctly_labeled = 0\n",
    "for i in range(len(observation)):\n",
    "    if output_state_seq[i]==original_result[i]:\n",
    "        correctly_labeled+=1\n",
    "print(\"ACCURACY OF THE ALGORITHM : \",correctly_labeled/len(observation)*100,\"%\")\n",
    "print(\"TIME TAKEN : \",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Testing Algorithm on entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to preprocess the test dataset into list of sentences to be fed to the Viterbi Algorithm\n",
    "\n",
    "def generate_test_data(test_set):\n",
    "\n",
    "    test_sentences=[]\n",
    "    test_original_outputs=[]\n",
    "    sentence = []\n",
    "    output = []\n",
    "    for test_case in test_set:\n",
    "        if test_case:\n",
    "            sentence.append(test_case[0])\n",
    "            output.append(test_case[1])\n",
    "        else:\n",
    "            \n",
    "            test_sentences.append(sentence)\n",
    "            test_original_outputs.append(output)\n",
    "            sentence=[]\n",
    "            output=[]\n",
    "    return test_sentences , test_original_outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences , test_original_outputs = generate_test_data(final_test_list_pos)\n",
    "print(\"Number of test sentences : \",len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For each of the test sentence we print :\n",
    "    1. x - The input observation\n",
    "    2. y - The original output state sequence\n",
    "    3. y_pred - The predicted output state sequence\n",
    "\"\"\"\n",
    " \n",
    "i=1\n",
    "for x,y in zip(test_sentences , test_original_outputs):\n",
    "    print(\"------------TEST CASE \",i,\" ------------------\")\n",
    "    print(\"Input x : \",x)\n",
    "    print(\"Original Output y : \",y)\n",
    "    \n",
    "    trelis , backpointer = Viterbi (tag_map , emmision_mat , transition_mat , init_dist , end_dist , x)\n",
    "    max_occur_list = backtrace_seq(backpointer)\n",
    "    y_pred = index_output_seq(max_occur_list , tag_map)\n",
    "\n",
    "    print(\"Predicted Output y_pred : \",y_pred)\n",
    "    print()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
